\section{Design Philosophy}

NormCode's design is guided by three core principles that address a fundamental tension in AI systems: the need for human oversight in processes that are increasingly automated.

\subsection{Dual-Readability: Bridging Human and Machine}

AI planning systems face a dilemma. Humans think in natural language; machines require unambiguous instructions. Most systems resolve this by forcing humans to write in a machine format (tedious, error-prone) or by letting machines interpret natural language (opaque, unauditable).

NormCode sidesteps this dilemma with \textbf{three isomorphic formats}: 
\texttt{.ncds}, intended for human authors and used for fast, intuitive authoring in natural language; 
\texttt{.ncd}, designed for the compiler or orchestrator as an unambiguous, machine-executable representation; 
and \texttt{.ncn}, intended for human reviewers as a readable narrative for verification before execution.


The key insight is that \textbf{these formats are not translations}---they are the same plan at different levels of explicitness. An author writes \texttt{.ncds}, the compiler enriches it to \texttt{.ncd} (adding types, bindings, flow indices), and a reviewer reads \texttt{.ncn} to verify the logic. No information is lost; no ambiguity is introduced. This allows domain experts (who may not understand the formal syntax) to audit AI workflows before they run.

\subsection{Progressive Formalization: From Sketch to Structure}

Traditional formal methods demand rigor upfront: you must specify everything before you can execute anything. This is impractical for AI workflows, where the ``right'' structure often emerges through experimentation.

NormCode supports \textbf{Progressive Formalization}---a lifecycle where plans start loose and tighten over time: (1) \textbf{Exploration Phase}: Write a rough \texttt{.ncds} sketch with vague concepts; (2) \textbf{Refinement Phase}: Run the plan, observe failures, and tighten inferences; (3) \textbf{Production Phase}: The plan is rigorous, auditable, and reliable.

This lifecycle is enabled by the semi-formal nature of NormCode (Section 3.6): the formalism only demands what the compiler needs. Everything else can remain flexible until you choose to lock it down.

\textbf{Intervenability} is a key feature. Because every step has a unique flow index, a user (or an automated system) can pause execution, inspect inputs, modify a concept's reference, or fork a run to explore alternative branches.

\subsection{Semantic vs. Syntactic Separation: Cost and Reliability Tracing}

Perhaps the most practically important design decision in NormCode is the clean separation between operations that invoke AI reasoning and operations that simply move data around.

In a typical NormCode plan, the majority of steps are syntactic. They collect inputs, select outputs, iterate over collections, and branch on conditions---all without any AI involvement. Only the ``thinking'' steps (imperatives and judgements) invoke an LLM.

This separation provides \textbf{Cost Visibility} (exact tracking of token usage), \textbf{Reliability Mapping} (localizing failures to probabilistic steps), and \textbf{Auditability} (generating reports on which steps invoked AI versus deterministic routing).

For high-stakes domains (legal, medical, financial), this transparency is often a regulatory requirement. NormCode makes it structural rather than aspirational.

\subsection{When to Use NormCode}

NormCode adds structure, and structure has costs. The framework is not appropriate for every use case:


\textbf{The sweet spot}: Complex, multi-step workflows where you need to know exactly what happened at each step---and where a failure in step 7 should not corrupt the reasoning in step 12.